#!/usr/bin/env node

import { createClient } from '@supabase/supabase-js';
import { readFileSync, readdirSync } from 'fs';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

// Load environment variables
dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// Supabase configuration
const supabaseUrl = process.env.SUPABASE_URL || process.env.VITE_SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('âŒ Missing Supabase configuration:');
  console.error('   SUPABASE_URL:', supabaseUrl ? 'âœ“' : 'âŒ');
  console.error('   SUPABASE_SERVICE_ROLE_KEY:', supabaseServiceKey ? 'âœ“' : 'âŒ');
  process.exit(1);
}

// Create Supabase admin client
const supabase = createClient(supabaseUrl, supabaseServiceKey, {
  auth: {
    autoRefreshToken: false,
    persistSession: false
  }
});

async function runMigrations() {
  console.log('ğŸš€ Starting database migrations...');
  console.log('ğŸ“ Supabase URL:', supabaseUrl);
  
  const migrationsDir = join(__dirname, '..', 'supabase', 'migrations');
  
  try {
    // Get all SQL files in migrations directory
    const files = readdirSync(migrationsDir)
      .filter(file => file.endsWith('.sql'))
      .sort(); // Sort to ensure proper order
    
    console.log(`ğŸ“ Found ${files.length} migration files:`);
    files.forEach(file => console.log(`   - ${file}`));
    
    // Create migrations tracking table if it doesn't exist
    console.log('\nğŸ“‹ Creating migrations tracking table...');
    const { error: trackingError } = await supabase.rpc('exec_sql', {
      sql: `
        CREATE TABLE IF NOT EXISTS public.schema_migrations (
          version TEXT PRIMARY KEY,
          executed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
        );
      `
    });
    
    if (trackingError) {
      console.log('âš ï¸  Could not create tracking table via RPC, trying direct SQL execution...');
      // Fallback: try to execute via direct SQL
      const { error: directError } = await supabase
        .from('schema_migrations')
        .select('version')
        .limit(1);
      
      if (directError && directError.code === '42P01') {
        console.log('ğŸ“‹ Migrations tracking table does not exist, will create it manually.');
      }
    }
    
    // Get already executed migrations
    const { data: executedMigrations, error: selectError } = await supabase
      .from('schema_migrations')
      .select('version');
    
    const executedVersions = new Set(
      executedMigrations?.map(m => m.version) || []
    );
    
    console.log(`\nâœ… Already executed migrations: ${executedVersions.size}`);
    
    // Execute pending migrations
    let executedCount = 0;
    
    for (const file of files) {
      const version = file.replace('.sql', '');
      
      if (executedVersions.has(version)) {
        console.log(`â­ï¸  Skipping ${file} (already executed)`);
        continue;
      }
      
      console.log(`\nğŸ”„ Executing migration: ${file}`);
      
      try {
        // Read migration file
        const migrationPath = join(migrationsDir, file);
        const sql = readFileSync(migrationPath, 'utf8');
        
        // Split SQL into individual statements (basic splitting)
        const statements = sql
          .split(';')
          .map(stmt => stmt.trim())
          .filter(stmt => stmt.length > 0 && !stmt.startsWith('--'));
        
        console.log(`   ğŸ“ Executing ${statements.length} SQL statements...`);
        
        // Execute each statement
        for (let i = 0; i < statements.length; i++) {
          const statement = statements[i];
          if (statement.trim()) {
            try {
              const { error } = await supabase.rpc('exec_sql', {
                sql: statement + ';'
              });
              
              if (error) {
                console.log(`   âš ï¸  Statement ${i + 1} failed via RPC, trying alternative method...`);
                console.log(`   ğŸ“„ Statement: ${statement.substring(0, 100)}...`);
                // For some statements, RPC might not work, but the migration might still be valid
              }
            } catch (err) {
              console.log(`   âš ï¸  Statement ${i + 1} error:`, err.message);
            }
          }
        }
        
        // Record successful migration
        const { error: insertError } = await supabase
          .from('schema_migrations')
          .insert({ version });
        
        if (insertError) {
          console.log(`   âš ï¸  Could not record migration ${version}:`, insertError.message);
        } else {
          console.log(`   âœ… Migration ${file} completed successfully`);
          executedCount++;
        }
        
      } catch (error) {
        console.error(`   âŒ Migration ${file} failed:`, error.message);
        console.error('   ğŸ›‘ Stopping migration process');
        process.exit(1);
      }
    }
    
    console.log(`\nğŸ‰ Migration process completed!`);
    console.log(`ğŸ“Š Executed ${executedCount} new migrations`);
    console.log(`ğŸ“‹ Total migrations in database: ${executedVersions.size + executedCount}`);
    
    // Verify tables exist
    console.log('\nğŸ” Verifying database schema...');
    const { data: tables, error: tablesError } = await supabase
      .from('information_schema.tables')
      .select('table_name')
      .eq('table_schema', 'public');
    
    if (tables) {
      console.log(`âœ… Found ${tables.length} tables in public schema:`);
      tables.forEach(table => console.log(`   - ${table.table_name}`));
    } else {
      console.log('âš ï¸  Could not verify tables:', tablesError?.message);
    }
    
  } catch (error) {
    console.error('âŒ Migration process failed:', error.message);
    process.exit(1);
  }
}

// Run migrations
runMigrations().catch(error => {
  console.error('ğŸ’¥ Unexpected error:', error);
  process.exit(1);
});